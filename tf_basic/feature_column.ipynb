{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[3.],\n",
      "       [4.],\n",
      "       [5.],\n",
      "       [6.]], dtype=float32)]\n",
      "use input_layer________________________________________\n",
      "[array([[3.],\n",
      "       [4.],\n",
      "       [5.],\n",
      "       [6.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "from tensorflow.python.feature_column.feature_column import _LazyBuilder\n",
    "\n",
    "def test_numeric():\n",
    "\n",
    "    price = {'price': [[1.], [2.], [3.], [4.]]}  # 4行样本\n",
    "    builder = _LazyBuilder(price)\n",
    "\n",
    "    def transform_fn(x):\n",
    "        return x + 2\n",
    "    #normalizer_fn: 对该特征下的所有数据进行转换\n",
    "    price_column = feature_column.numeric_column('price', normalizer_fn=transform_fn)\n",
    "    #使用_LazyBuilder和inpu_layer来分别进行了测试.效果是一样的.\n",
    "    price_transformed_tensor = price_column._get_dense_tensor(builder)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        print(session.run([price_transformed_tensor]))\n",
    "\n",
    "    # 使用input_layer\n",
    "\n",
    "    price_transformed_tensor = feature_column.input_layer(price, [price_column])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([price_transformed_tensor]))\n",
    "        \n",
    "test_numeric()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "def test_bucketized_column():\n",
    "\n",
    "    price = {'price': [[5.], [15.], [25.], [35.]]}  # 4行样本\n",
    "\n",
    "    price_column = feature_column.numeric_column('price')\n",
    "    #source_column: 必须是numeric_column\n",
    "    #boundaries: 不同的桶。boundaries=[0., 1., 2.],产生的bucket就是, (-inf, 0.), [0., 1.), [1., 2.), and [2., +inf), 每\n",
    "    #一个区间分别表示0, 1, 2, 3,所以相当于分桶分了4个.\n",
    "    bucket_price = feature_column.bucketized_column(price_column, [0, 10, 20, 30, 40])\n",
    "\n",
    "    price_bucket_tensor = feature_column.input_layer(price, [bucket_price])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        print(session.run([price_bucket_tensor]))\n",
    "        \n",
    "#我们看到分桶之后，会直接转换成one-hot形式的。\n",
    "test_bucketized_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "def test_categorical_column_with_vocabulary_list():\n",
    "\n",
    "    color_data = {'color': [['R', 'R'], ['G', 'R'], ['B', 'G'], ['A', 'A']]}  # 4行样本\n",
    "\n",
    "    builder = _LazyBuilder(color_data)\n",
    "    #categorical_column_with_vocabulary_list来说返回的是sparser_tensor\n",
    "    #注意 id_tensor 这个是有效的，另外一个是None. 对于线性模型来说是可以直接使用sparser_tensor的\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "    )\n",
    "\n",
    "    color_column_tensor = color_column._get_sparse_tensors(builder)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print(session.run([color_column_tensor.id_tensor]))\n",
    "    #对于深度模型来说，需要将sparser转换成dense，所以也就有了indicator_column 这个函数的出现。\n",
    "    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot\n",
    "    #indicator_column的作用就是将category产生的sparser tensor转换成dense tensor.\n",
    "    color_column_identy = feature_column.indicator_column(color_column)\n",
    "    #input_layer: 只接受dense tensor\n",
    "    color_dense_tensor = feature_column.input_layer(color_data, [color_column_identy])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        #tables_initializer: 在sparser的时候使用的，如果不进行初始化会出现 Table not initialized.\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([color_dense_tensor]))\n",
    "        \n",
    "test_categorical_column_with_vocabulary_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 0],\n",
      "       [3, 0]]), values=array([5, 2, 6, 3]), dense_shape=array([4, 1]))]\n",
      "use input_layer________________________________________\n",
      "[array([[0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "def test_categorical_column_with_hash_bucket():\n",
    "\n",
    "    color_data = {'color': [['R'], ['G'], ['B'], ['A']]}  # 4行样本\n",
    "    builder = _LazyBuilder(color_data)\n",
    "    #当category的数量很多，也就无法使用指定category的方法来处理了，那么，可以使用这种哈希分桶的方式来进行处理\n",
    "    #毕竟对于hash_bucket来说，对于bucket_size的选取是个问题\n",
    "    color_column = feature_column.categorical_column_with_hash_bucket('color', 7)\n",
    "    color_column_tensor = color_column._get_sparse_tensors(builder)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        print(session.run([color_column_tensor.id_tensor]))\n",
    "\n",
    "    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot\n",
    "    color_column_identy = feature_column.indicator_column(color_column)\n",
    "    color_dense_tensor = feature_column.input_layer(color_data, [color_column_identy])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([color_dense_tensor]))\n",
    "        \n",
    "#从上面看这种hash分桶的方法，在hash_size的选择上是很重要的\n",
    "#现在选择3，对于R 和 B 来说分桶到一个烈面了；对于 G和A 分桶到一个里面了\n",
    "#当将 hash_size=7来测试, R G B A就都分到了不同的桶中，所以值越大也容易精确的分桶.\n",
    "test_categorical_column_with_hash_bucket()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeding________________________________________\n",
      "[array([[-0.4109104 , -0.331495  ,  0.05539821, -0.40729854,  0.43970883],\n",
      "       [-0.30821052, -0.08916157,  0.6836008 , -0.4465533 , -0.25365806],\n",
      "       [-0.5803039 , -0.06652644, -0.4100606 , -0.16685905, -0.19076806],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "def test_embedding():\n",
    "    color_data = {'color': [['R'], ['G'], ['B'], ['A']]}  # 4行样本\n",
    "\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "    )\n",
    "    #每一个都会转换成5个维度的数据，并且使用高斯分布来进行初始化。\n",
    "    #因为A 没有在catergorical_column中出现，所以使用了0进行初始化.\n",
    "    color_embeding = feature_column.embedding_column(color_column, 5)\n",
    "    color_embeding_dense_tensor = feature_column.input_layer(color_data, [color_embeding])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('embeding' + '_' * 40)\n",
    "        print(session.run([color_embeding_dense_tensor]))\n",
    "        \n",
    "test_embedding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted categorical----------------------------------------\n",
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 0],\n",
      "       [3, 0]]), values=array([ 0,  1,  2, -1]), dense_shape=array([4, 1]))]\n",
      "----------------------------------------\n",
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 0],\n",
      "       [3, 0]]), values=array([1., 2., 4., 8.], dtype=float32), dense_shape=array([4, 1]))]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "def test_weighted_categorical_column():\n",
    "    color_data = {'color': [['R'], ['G'], ['B'], ['A']],\n",
    "                  'weight': [[1.0], [2.0], [4.0], [8.0]]}  # 4行样本\n",
    "\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "    )\n",
    "\n",
    "    color_weight_categorical_column = feature_column.weighted_categorical_column(color_column, 'weight')\n",
    "\n",
    "    builder = _LazyBuilder(color_data)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        id_tensor, weight = color_weight_categorical_column._get_sparse_tensors(builder)\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('weighted categorical' + '-' * 40)\n",
    "\n",
    "        print(session.run([id_tensor]))\n",
    "        print('-' * 40)\n",
    "        print(session.run([weight]))\n",
    "\n",
    "test_weighted_categorical_column()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "#对所有特征进行线性加权操作\n",
    "def get_linear_model_bias():\n",
    "    with tf.variable_scope('linear_model', reuse=True):\n",
    "        return tf.get_variable('bias_weights')\n",
    "def get_linear_model_column_var(column):\n",
    "    return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                             'linear_model/' + column.name)[0]\n",
    "def test_linear_model():\n",
    "    \"\"\"\n",
    "    测试线性模型\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    featrues = {\n",
    "        'price': [[1.0], [5.0], [10.0]],\n",
    "        'color': [['R'], ['G'], ['B']]\n",
    "    }\n",
    "    price_column = feature_column.numeric_column('price')\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list('color', ['R', 'G', 'B'])\n",
    "    prediction = feature_column.linear_model(featrues, [price_column, color_column])\n",
    "\n",
    "    bias = get_linear_model_bias()\n",
    "    price_var = get_linear_model_column_var(price_column)\n",
    "    color_var = get_linear_model_column_var(color_column)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "\n",
    "        sess.run(bias.assign([7.0]))\n",
    "        sess.run(price_var.assign([[10.0]]))\n",
    "        sess.run(color_var.assign([[2.0], [2.0], [2.0]]))\n",
    "\n",
    "        predication_result = sess.run([prediction])\n",
    "\n",
    "        print(predication_result)\n",
    "\n",
    "test_linear_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use input_layer________________________________________\n",
      "[array([[0., 0., 0., 0., 0., 0., 0., 0., 4., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 2., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 0., 2., 0.]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "def test_crossed_column():\n",
    "    \"\"\"\n",
    "    crossed column测试\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    featrues = {\n",
    "        'price': [['A', 'A'], ['B', 'D'], ['C', 'A']],\n",
    "        'color': [['R', 'R'], ['G', 'G'], ['B', 'B']]\n",
    "    }\n",
    "\n",
    "    price = feature_column.categorical_column_with_vocabulary_list('price', ['A', 'B', 'C', 'D'])\n",
    "    color = feature_column.categorical_column_with_vocabulary_list('color', ['R', 'G', 'B'])\n",
    "    p_x_c = feature_column.crossed_column([price, color], 16)\n",
    "\n",
    "    p_x_c_identy = feature_column.indicator_column(p_x_c)\n",
    "\n",
    "    p_x_c_identy_dense_tensor = feature_column.input_layer(featrues, [p_x_c_identy])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([p_x_c_identy_dense_tensor]))\n",
    "\n",
    "test_crossed_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
